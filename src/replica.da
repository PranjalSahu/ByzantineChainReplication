import nacl.encoding
import nacl.signing
import nacl.hash
from nacl.bindings.utils import sodium_memcmp
import pickle
import itertools
import logging
import os
import time

STATUS  = import_da('status').STATUS
Request = import_da('request').Request
OPTYPE  = import_da('request').OPTYPE
logger  = logging.getLogger('main_logger')


class Replica(process):
    def setup(state: dict, 
        _slot_num: int, 
        timeout: int, 
        public_keys: list, 
        private_key: object, 
        status: STATUS, 
        head: bool, 
        tail: bool, 
        next_replica: Replica,
        prev_replica: Replica, 
        head_replica: Replica,
        failures: list,
        index: int,
        olympus: Olympus,
        configuration: int,
        checkpoint_interval: int):

        # Create counter for slot numbers... This is only used by the head
        self.slot_counter = itertools.count(self._slot_num+1)
        # Assume slot numbers start at 0
        self.last_slot_number = self._slot_num
        # Create the processing list
        self.processing_list = []
        # Create the cache
        self.cache = {}
        # hash for storing number of requests received from a client
        self.client_requests = {}
        # hash for storing number of requests receieved from a client which are coming from previous replica
        self.shuttle_requests = {}
        # hash for storing number of result shuttle
        self.result_shuttle_requests = {}

        logger.debug("Got checkpoint_interval: " + str(checkpoint_interval))

        # All the trigger flags
        self.crash              = False
        self.drop_result_stmt   = False
        self.change_operation   = False
        self.change_result      = False
        self.truncate_history_flag   = False
        self.truncate_history_n = 0
        self.sleep_flag         = False
        self.sleep_flag_time    = 0
        self.drop_flag          = False
        self.extra_op_flag      = False
        self.invalid_order_sig_flag  = False
        self.invalid_result_sig_flag = False
        self.drop_checkpt_stmts_flag = False
        self.increment_slot_flag     = False

        self.failure_string   =  ""
        self.configuration    = configuration
        self.order_history    = {}                            # for storing the order history and the proofs

        self.wedge_requests_count                 = 0         # number of wedge requests received
        self.new_configuration_count              = 0         # number of reconfiguration requests received
        self.checkpoint_count                     = 0         # number of checkpoint requests received
        self.completed_checkpoint_count           = 0         # number of completed checkpoint shuttle received
        self.get_running_state_count              = 0         # number of get_running_state requests received
        self.catch_up_count                       = 0         # number of catch_up requests received
        self.latest_checkpoint_proof = []
        self.latest_checkpoint_slot = 0
    
    def crash_condition():
        return self.crash
    
    def update_trigger_flags_new(flag):
        count_to_compare = -1
        if flag == 4:       # DONE
            self.wedge_requests_count   = self.wedge_requests_count+1
            count_to_compare            = self.wedge_requests_count
        elif flag == 5:
            self.new_configuration_count = self.new_configuration_count+1
            count_to_compare             = self.new_configuration_count
        elif flag == 6:     # DONE
            self.checkpoint_count  = self.checkpoint_count+1
            count_to_compare       = self.checkpoint_count
        elif flag == 7:     # DONE
            self.completed_checkpoint_count = self.completed_checkpoint_count+1
            count_to_compare                = self.completed_checkpoint_count
        elif flag == 8:
            self.get_running_state_count = self.get_running_state_count+1
            count_to_compare             = self.get_running_state_count
        elif flag == 9:     # DONE
            self.catch_up_count          = self.catch_up_count+1
            count_to_compare             = self.catch_up_count

        # inject_error(temphash, request, flag)
        # temphash and request are empty for this case since we don't need the count
        # of requests based on clientId and we dont need to compare the client_id's request
        inject_error({}, [], flag, count_to_compare, 1)
        return

    def update_trigger_flags(request, flag):
        if flag == 0:
            if request.client_id in self.client_requests:
                self.client_requests[request.client_id] = self.client_requests[request.client_id] + 1
            else:
                self.client_requests[request.client_id] = 1
            temphash = self.client_requests
        elif flag == 1:
            if request.client_id in self.shuttle_requests:
                self.shuttle_requests[request.client_id] = self.shuttle_requests[request.client_id] + 1
            else:
                self.shuttle_requests[request.client_id] = 1
            temphash  = self.shuttle_requests
        elif flag == 2:
            if request.client_id in self.result_shuttle_requests:
                self.result_shuttle_requests[request.client_id] = self.result_shuttle_requests[request.client_id] + 1
            else:
                self.result_shuttle_requests[request.client_id] = 1
            temphash = self.result_shuttle_requests

        # Injecting errors based on the counts updated
        inject_error(temphash, request, flag, 0, 0)
        return

    def trigger_error_helper(f, temphash, request, flag, checkhash, client_string):
        if f[0] == OPTYPE.CRASH:              #DONE # crash the replica
            self.crash = True
            self.failure_string = checkhash[flag]+'('+str(f[2][0])+','+client_string+')'+',crash()'
            logger.error('crash TRIGGER FLAG CRASH UPDATED TO TRUE '+str(flag)+' '+self.failure_string)
            # Kill the process
            logging.shutdown()
            exit(-1)
        elif f[0] == OPTYPE.DROPRESULTSTMT:   #DONE # drop result shuttle
            self.drop_result_stmt = True
            self.failure_string = checkhash[flag]+'('+str(f[2][0])+','+client_string+')'+',drop_result_stmt()'
            logger.error('drop_result_stmt TRIGGER DROP SHUTTLE UPDATED TO TRUE '+str(flag)+' '+self.failure_string)
        elif f[0] ==  OPTYPE.CHANGEOPERATION: #DONE # change operation
            self.change_operation = True
            self.failure_string = checkhash[flag]+'('+str(f[2][0])+','+client_string+')'+',change_operation()'
            logger.error('change_operation TRIGGER CHANGE OPERATION UPDATED TO TRUE '+str(flag)+' '+self.failure_string)
        elif f[0] == OPTYPE.CHANGERESULT:     #DONE # change result
            self.change_result = True
            self.failure_string = checkhash[flag]+'('+str(f[2][0])+','+client_string+')'+',change_result()'
            logger.error('change_result TRIGGER CHANGE RESULT UPDATED TO TRUE '+str(flag)+' '+self.failure_string)
        elif f[0] == OPTYPE.TRUNCATEHISTORY:
            self.truncate_history_flag = True
            self.truncate_history_n    = f[2][2]
            self.failure_string = checkhash[flag]+'('+str(f[2][1])+')'+',truncate_history('+str(self.truncate_history_n)+')'
            logger.error('truncate_history_flag TRIGGER UPDATED TO TRUE '+self.failure_string)
        elif f[0] == OPTYPE.SLEEP:
            self.sleep_flag = True
            self.sleep_flag_time = f[2][2]
            self.failure_string = checkhash[flag]+'('+str(f[2][1])+')'+',sleep('+str(self.sleep_flag_time)+')'
            logger.error('sleep_flag TRIGGER UPDATED TO TRUE '+self.failure_string)
            #time.sleep(self.sleep_flag_time)     # calling sleep method error
            self.sleep_flag = False
            self.sleep_flag_time = 0
            logger.error('sleep_flag TRIGGER UPDATED TO FALSE ')
        elif f[0] == OPTYPE.ONLYDROP:           #DONE
            self.drop_flag = True
            self.failure_string = checkhash[flag]+'('+str(f[2][1])+')'+',drop()'
            logger.error('drop_flag TRIGGER UPDATED TO TRUE '+self.failure_string)
        elif f[0] == OPTYPE.INCREMENTSLOT:
            self.increment_slot_flag = True
            self.failure_string = checkhash[flag]+'('+str(f[2][1])+')'+',increment_slot()'
            logger.error('increment_slot_flag TRIGGER UPDATED TO TRUE '+self.failure_string)
        elif f[0] == OPTYPE.EXTRAOP:
            self.extra_op_flag = True
            self.failure_string = checkhash[flag]+'('+str(f[2][1])+')'+',extra_op()'
            logger.error('extra_op_flag TRIGGER UPDATED TO TRUE '+self.failure_string)
        elif f[0] == OPTYPE.INVALIDORDERSIG:
            self.invalid_order_sig_flag = True
            self.failure_string = checkhash[flag]+'('+str(f[2][1])+')'+',invalid_order_sig()'
            logger.error('invalid_order_sig_flag TRIGGER UPDATED TO TRUE '+self.failure_string)
        elif f[0] == OPTYPE.INVALIDRESULTSIG:
            self.invalid_result_sig_flag = True
            self.failure_string = checkhash[flag]+'('+str(f[2][1])+')'+',invalid_result_sig()'
            logger.error('invalid_result_sig_flag TRIGGER UPDATED TO TRUE '+self.failure_string)
        elif f[0] == OPTYPE.DROPCHECKPTSTMTS:
            self.drop_checkpt_stmts_flag = TRUE #DONE
            self.failure_string = checkhash[flag]+'('+str(f[2][1])+')'+',drop_checkpt_stmts()'
            logger.error('drop_checkpt_stmts_flag TRIGGER UPDATED TO TRUE '+self.failure_string)
        return

    # After all the counts are set it checks if conditions are matched and sets the required flag for failure
    # This will include both phase 2 and phase 3 errors
    def inject_error(temphash, request, tempflag, count_to_compare_local, checkflag):
        checkhash    = {}
        checkhash[0] = 'client_request'
        checkhash[1] = 'shuttle'
        checkhash[2] = 'result_shuttle'
        checkhash[3] = 'empty'
        checkhash[4] = 'wedge_request'
        checkhash[5] = 'new_configuration'
        checkhash[6] = 'checkpoint'
        checkhash[7] = 'completed_checkpoint'
        checkhash[8] = 'get_running_state'
        checkhash[9] = 'catch_up'
        
        reason_string = checkhash[tempflag]

        for f in failures:
            #logger.debug('FAILURE REQUESTS ARE ' + str(request.client_id) + str(temphash[request.client_id]))
            if checkflag == 0 and f[1] == checkhash[tempflag] and f[2][0] == request.client_id and f[2][1] == temphash[request.client_id] and f[3] == self.configuration:
                trigger_error_helper(f, temphash, request, tempflag, reason_string, str(request.client_id))
            elif checkflag == 1 and f[1] == checkhash[tempflag] and count_to_compare_local == f[2][1] and f[3] == self.configuration:
                trigger_error_helper(f, temphash, request, tempflag, reason_string, "")
        return


    def run():
        await(False)

    # Relates to order command transition at replica. Issues an order command and returns a hashed result
    def order_command(req):
        # Cast input to strings
        key = str(req.key)
        val = str(req.value)

        if change_operation:
            req.op = OPTYPE.GET
            change_operation =  False
            logger.error('CHANGING OPERATION FAILURE ' + str(key) +'  '+str(val))

        success = False
        results = 'fail'
        if req.op == OPTYPE.PUT:
            logger.debug("Order Command Put")
            self.state[key] = val
            results = 'OK'
            success = True
        elif req.op == OPTYPE.GET:
            logger.debug("Order Command Get")
            success = True
            if self.state.get(key):
                results = self.state.get(key)
            else:
                results = ''
        elif req.op == OPTYPE.SLICE:
            logger.debug("Order Command Slice")
            s = self.state.get(key)
            # Check if the value exists
            if s:
                i, j = req.value  # Todo: Prevent this from throwing when not a valid tuple
                # Check i and j indices
                if 0 <= i and i < j and j < len(s):
                    self.state[key] = self.state[key][i:j]
                    success = True
                    results = 'OK'
        elif req.op == OPTYPE.APPEND:
            logger.debug("Order Command APpend")
            if self.state.get(key):
                self.state[key] = self.state[key] + val
                success = True
                results = 'OK'

        logger.debug("Order Command2")
        if change_result:
            results = 'OK'
            change_result =  False
            logger.error('INSERTING CHANGE RESULT FAILURE ' + str(results)+ '  ' +str(success))

        return success, results

    def validate_checkpoint_proof_forward(checkpoint_proof):
        n = len(checkpoint_proof)
        if n < index+1:
            return False
        for i, proof in enumerate(checkpoint_proof):
            try:
                self.public_keys[i].verify(proof)
            except:
                logger.error("----Checkpoint Proof Signature Validation Error---")
                return False
        for i in range(1, index+1):
            if checkpoint_proof[i].message !=  checkpoint_proof[i-1].message:
                return False
        return True

    def validate_checkpoint_proof_backward(checkpoint_proof):
        n = len(checkpoint_proof)
        if n !=  len(public_keys):
            return False
        for i, proof in enumerate(checkpoint_proof):
            try:
                self.public_keys[i].verify(proof)
            except:
                logger.error("----Checkpoint Proof Signature Validation Error---")
                return False
        for i in range(1, n):
            if checkpoint_proof[i].message !=  checkpoint_proof[i-1].message:
                return False
        return True

    def send_reconfig(reason):
        # Become immutable and send reconfigure request
        self.status = STATUS.IMMUTABLE
        body = (reason, self.configuration, [])
        send(("ReConfig", body), to=self.olympus)

    # Performs outgoing actions
    def forward_results(req, order_proofs, result_proofs, order_stmt, result_stmt, result, checkpoint_num, checkpoint_proof):
        # Sign the order statement and add it to the order proof
        signed_order_stmt  = self.private_key.sign(pickle.dumps(order_stmt))
        order_proofs.append(signed_order_stmt)

        # Sign the result statement and add it to the result proof
        signed_result_stmt = self.private_key.sign(pickle.dumps(result_stmt))
        result_proofs.append(signed_result_stmt)

        # Forward results
        if self.tail:
            payload = (result, result_proofs, req.request_id)
            send(("Response", payload), to=req.client)
            logger.debug("Sent Response," + str(result) + " to Client: "  + str(req.client_id) + " for Request ID: " +
                         str(req.request_id))
            logger.debug("Request ID: " + str(req.request_id) + " -- " + str(req.get_body()))
            logger.debug("State:" + str(self.state))

            # Do validation...
            # Todo: Deduplicate this code
            if validate_result_proof(result_proofs):
                # If valid, add to cache
                self.cache[req.get_body()] = (result, result_proofs)
                
                # validate the checkpoint_proof
                if checkpoint_num:
                    if validate_checkpoint_proof_backward(checkpoint_proof):
                        # Todo: Should we check to make sure that this is the greatest checkpoint?
                        self.latest_checkpoint_proof = checkpoint_proof
                        self.latest_checkpoint_slot = checkpoint_num
                        return_payload = (req.get_body(), result, result_proofs, checkpoint_num, checkpoint_proof)
                        update_trigger_flags_new(7) # update the trigger for tail replica
                    else:
                        logger.error("Validation of checkpoint proof failed. Becomming immutable and sending a reconfig request to Olympus")
                        send_reconfig('CheckpointProof')
                        return
                else:
                    return_payload = (req.get_body(), result, result_proofs, 0, [])

                # Send return shuttles if we are not the head
                if not self.head:
                    # Forward the result shuttle to the previous replica
                    send(("ResultShuttle", return_payload), to=self.prev_replica)
                    logger.debug("Sent Return Shuttle for Client: " + str(req.client_id) + " Request ID: " +
                                 str(req.request_id) + " to Replica:" + str(self.prev_replica))
            else:
                # Reconfigure
                logger.error("1 Validation of result shuttle failed. Becomming immutable and sending a reconfig request to Olympus")
                send_reconfig('ResultShuttle')
                return None
        else:
            # Send to the next replica
            if drop_result_stmt:
                order_proofs     = order_proofs[1:]
                result_proofs    = result_proofs[1:]
                drop_result_stmt = False
                logger.error('----FAILURE INJECTION DROPPING THE RESULT PROOF OF HEAD -------')

            if checkpoint_num:
                if validate_checkpoint_proof_forward(checkpoint_proof):
                    payload = (req.get_body(), order_proofs, result_proofs, checkpoint_num, checkpoint_proof)
                else:
                    logger.error("Validation of checkpoint proof failed. Becomming immutable and sending a reconfig request to Olympus")
                    send_reconfig('CheckpointProof')
                    return
            else:
                payload = (req.get_body(), order_proofs, result_proofs, 0, [])

            update_trigger_flags(req, 1)
            send(("Order", payload), to=self.next_replica)
            logger.debug("Sent Response," + str(result) + ", for Client:" + str(req.client_id) + "Request ID:"
                         + str(req.request_id) + " to Replica:" + str(self.next_replica))

    # Core logic for receiving a new request
    #   req is a Request object
    def process_new_request(req):
        # Todo: Do validation

        # Make sure our status is Active
        if self.status != STATUS.ACTIVE:
            # Send an Error response and exit
            return send(("Error", ("Not Active", req.request_id)), to=req.client)

        # Check if we are the head, exit if we aren't
        if not self.head:
            return send(("Error", ("Did not send to the head replica", req.request_id)), to=req.client)

        if self.increment_slot_flag:
            logger.error('[ERROR INJECTION] Incrementing  the slot number: current is '+str(self.slot_counter))
            next(self.slot_counter)
            self.increment_slot_flag = False

        # Todo: Do more validation? Check for valid signing keys from client, etc...

        # Generate a slot number. By definition, the head does not have holes
        self.last_slot_number = next(self.slot_counter)
        logger.debug("Slot Number: " + str(self.last_slot_number))

        # Generate the order statement
        order  = req  # Retain the semantics of the paper
        result = order_command(order)
        hashed_result = nacl.hash.sha256(pickle.dumps(result))
        order_stmt    = (self.last_slot_number, order)
        result_stmt   = (order, hashed_result)
        order_proofs  = []
        result_proofs = []

        # Update history
        self.order_history[self.last_slot_number] = (order_proofs, result_proofs)

        if (self.last_slot_number+1)%checkpoint_interval == 0:   # check if checkpoint interval condition is satisfied
            hashed_state     = nacl.hash.sha256(pickle.dumps(state))
            checkpoint_num   = self.last_slot_number
            checkpoint_proof = []
            signed_hashed_state = self.private_key.sign(hashed_state)
            checkpoint_proof.append(signed_hashed_state)
            logger.info('[Checkpoint] '+str(self.last_slot_number))
            update_trigger_flags_new(6)
        else:
            checkpoint_num   = 0
            checkpoint_proof = []
        return forward_results(req, order_proofs, result_proofs, order_stmt, result_stmt, result, checkpoint_num, checkpoint_proof)

    # Handler for new requests
    def receive(msg=("Request", body), from_=client):
        # Parse Request
        request = Request.from_body(body)
        logger.debug("Received New Request ID: " + str(request.request_id)+" --->>>  "+str(request.op)+', '+str(request.key)+', '+str(request.value))

        update_trigger_flags(request, 0)  #client_requests triggers

        if self.drop_flag:       # drop if the drop_flag is True
            self.drop_flag = False
            return

        return process_new_request(request)

    # Validates order proof signatures and contents
    def validate_order_proofs(order_proofs):
        # Check length of order_proofs
        if len(order_proofs) != self.index:
            logger.error("----Order Proof Error: Truncated Proofs----")
            return False

        first_proof = order_proofs[0]
        # Check for valid order proof signatures
        for i, proof in enumerate(order_proofs):
            try:
                self.public_keys[i].verify(proof)
            except:
                logger.error("----Order Proof Signature Validation Error---")
                return False

        # Check for valid order proof contents
        for proof in order_proofs:
            if proof.message != first_proof.message:
                logger.error("----Order Proof Content Validation Error--- ")
                return False

        # No errors
        return True

    # Duplicate code in client.da
    def validate_result_proof(result_proof):
        # Check for truncation
        if len(result_proof) != len(self.public_keys):
            return False

        # Check for valid proof signatures
        for i, proof in enumerate(result_proof):
            try:
                self.public_keys[i].verify(proof)
            except:
                logger.error("----Result Proof Signature Validation Error---")
                return False

        # Hash the result
        first_result_stmt = pickle.loads(result_proof[0].message)
        orig_order, response_hash = first_result_stmt
        for proof in result_proof:
            order, result_hash = pickle.loads(proof.message)
            # Compare order command contents
            if not orig_order.get_body() == order.get_body():
                logger.error("---Result Proof Order Validation Error---")
                return False
            # Compare result hash
            if not sodium_memcmp(response_hash, result_hash):
                logger.error("---Result Proof Hash Validation Error---")
                return False

        return True

    # Process pending orders if there are no holes in slot number
    def process_ready_orders(order_proofs, result_proofs):
        # Check for holes
        self.processing_list.sort()
        for pending in self.processing_list:
            current_slot, request, checkpoint_num, checkpoint_proof = pending
            if (self.last_slot_number + 1) == current_slot:
                logger.debug("No holes. Committing Slot: " + str(current_slot))
                # Generate the order statement
                # Note: This is duplicate code from process_new_request
                order  = request  # Retain the semantics of the paper
                result = order_command(order)
                hashed_result = nacl.hash.sha256(pickle.dumps(result))
                order_stmt    = (current_slot, order)
                result_stmt   = (order, hashed_result)

                # Update the last slot number
                self.last_slot_number = current_slot
                self.order_history[current_slot] = (order_proofs, result_proofs)

                # Remove from processing list
                if checkpoint_num:
                    hashed_state = nacl.hash.sha256(pickle.dumps(self.state))
                    signed_hashed_state = self.private_key.sign(hashed_state)
                    checkpoint_proof.append(signed_hashed_state)
                else:
                    checkpoint_num   = 0
                    checkpoint_proof = []
                self.processing_list.remove(pending)
                if not forward_results(request, order_proofs, result_proofs, order_stmt, result_stmt, result, checkpoint_num, checkpoint_proof):
                    return False

    # Handle order commands from replicas. An order message is sent to the next replica in the list
    def receive(msg=("Order", m), from_=replica):
        # Parse message
        body, order_proofs, result_proofs, checkpoint_num, checkpoint_proof = m
        request = Request.from_body(body)
        logger.debug("Received Order Command for Client: " + str(request.client_id) + " Request ID:" +
                     str(request.request_id))

        update_trigger_flags(request, 1)    # shuttle triggers
        if checkpoint_num:
            update_trigger_flags_new(6)     # update trigger for checkpoint message
        if self.drop_flag:                       # drop if the drop_flag is True      
            self.drop_flag = False
            return

        # Make sure we got a message from the correct replica
        if replica != self.prev_replica:
            # Todo: Should we report misbehavior?
            logger.error("Received an order command from invalid sender")
            return
        # Make sure our status is active
        elif self.status != STATUS.ACTIVE:
            # Do nothing
            logger.debug("Received an order command while not active... Not going to do anything.")
            # Todo: Should we send a reconfig to Olympus?
            return
        else:
            # Do validation
            logger.debug("Validating order proofs for Client: " + str(request.client_id) + " Request ID:"
                         + str(request.request_id))
            order_proofs_valid = validate_order_proofs(order_proofs)
            if order_proofs_valid:
                logger.debug("Order Proof Signatures and Contents Validated for Client: " + str(request.client_id) +
                             " Request ID: " + str(request.request_id))
            else:
                # Validation error... become immutable and reconfigure
                logger.error('Order proof validaiton error. Issuing a reconfig from Olympus')
                send_reconfig('OrderProof')
                return

            slot = pickle.loads(order_proofs[0].message)[0]

            # Add the order to the pending orders list
            pending_order = (slot, request, checkpoint_num, checkpoint_proof)
            self.processing_list.append(pending_order)
            # Attempt to commit ready orders
            return process_ready_orders(order_proofs, result_proofs)

    # delete history when getting the checkpoint return shuttle
    def delete_history(checkpoint_num):
        to_delete = []
        for k in order_history:
            if k <= checkpoint_num:
                to_delete.append(k)
        for k in to_delete:
            order_history.pop(k)
        return

    # Handler for client retransmission
    def receive(msg=("Retransmission", body), from_=client):
        # Parse Request
        request = Request.from_body(body)
        logger.debug("Received Retransmit for Client: " + str(request.client_id) + " Request ID" + str(request.request_id))

        update_trigger_flags(request, 0) #
        if self.drop_flag:       # return if drop_flag is True
            self.drop_flag = False
            return
        # Make sure our status is Active
        if self.status != STATUS.ACTIVE:
            logger.error("We are not active for this retransmission")
            # Send an Error response and exit
            return send(("Error", ("Not Active", request.request_id)), to=client)
        # Check the cache for a response
        elif self.cache.get(body):
            logger.debug("Found in cache")
            cached_result, cached_result_proof = self.cache.get(body)
            # Return the cached result
            payload = (cached_result, cached_result_proof, request.request_id)
            logger.debug("Send cached result for Client: " + str(request.client_id) + " Request ID: "
                         + str(request.request_id))
            return send(("Response", payload), to=client)
        else:
            # Check if we are the head replica
            if self.head:
                # Check if there is a pending request (ie. There is a request in the sent list with the request_id)
                pending_request = some(sent(("Order", (b, _, _))), has= b==body)
                logger.info("Pending: " + str(pending_request))
                if pending_request:
                    logger.debug("Pending request for Client: " + str(request.client_id) + " Request ID: " + str(request.request_id))
                    # Wait for a result shuttle response with a timeout
                    # Todo: Await for a proof that is valid... validate
                    if await(some(received(("ResultShuttle", (b, r, r_proofs,))), has= b==body)):
                        # Check status, which can change while we await
                        if self.status == STATUS.ACTIVE:
                            # Get the response from the shuttle and send the response to the client and exit
                            payload = (r, r_proofs, request.request_id)
                            return send("Response", payload, to=client)
                    # No response obtained
                    elif timeout(timeout):
                        # Become immutable and reconfigure
                        logger.error("HEAD replica became IMMUTABLE due to timeout since result proof shuttle not received for Request ID: " +
                            str(request.request_id))
                        send_reconfig('ResultShuttle')
                        return
                else:
                    # Treat this retransmission as a new request
                    logger.debug("Treating Retransmission as a New Request")

                    return process_new_request(request)
            # If we are not the head replica
            else:
                # Forward the request to the head replica and set a timer
                head_replica = self.head_replica
                send(("Retransmission", body), to=head_replica)

                # Wait for a result shuttle response with a timeout
                # Todo: Await for a proof that is valid... validate
                if await(some(received(("ResultShuttle", (b, r, r_proofs,))), has=b == body)):
                    # Check status, which can change while we await
                    if self.status == STATUS.ACTIVE:
                        # Get the response from the shuttle and send the response to the client and exit
                        payload = (r, r_proofs, request.request_id)
                        return send("Response", payload, to=client)
                # No response obtained
                elif timeout(timeout):
                    # Reconfigure
                    logger.error("NON HEAD replica became IMMUTABLE due to timeout since result proof shuttle not received for Request ID: " +
                            str(request.request_id))
                    send_reconfig('ResultShuttle')
                    return

    # Handler for the result shuttle
    def receive(msg=("ResultShuttle", m), from_=sender):
        # Parse Message
        body, result, result_proofs, checkpoint_num, checkpoint_proof = m
        request = Request.from_body(body)
        logger.debug("Received Result Shuttle for Client: " + str(request.client_id) + " Request ID: " +
                     str(request.request_id) + " from: " + str(sender))

        update_trigger_flags(request, 2)
        if checkpoint_num:
            update_trigger_flags_new(7)          # update trigger for Completed Checkpoint
        if self.drop_flag:                       # drop if drop_flag is True
            self.drop_flag = False
            return

        # Todo: Validate sender identity? Should we care or is validating the result proof enough?

        # Validate result proof
        if validate_result_proof(result_proofs):
            logger.debug("Validated Result Shuttle for Client " + str(request.client_id) + " Request ID: " +
                         str(request.request_id) + " from:" + str(sender))
            # Add valid result to cache
            self.cache[body] = (result, result_proofs)

            if checkpoint_num:
                if validate_checkpoint_proof_backward(checkpoint_proof):
                    # Todo: Should we check to make sure that this is the greatest checkpoint?
                    self.latest_checkpoint_proof = checkpoint_proof
                    self.latest_checkpoint_slot  = checkpoint_num
                    delete_history(checkpoint_num)
                    
                    # Drop checkpoint proofs of first t+1 replicas if the flag is True
                    if self.drop_checkpt_stmts_flag:
                        logger.info("Dropping checkpoint proof statements")
                        self.drop_checkpt_stmts_flag = False
                        tp_temp = int((len(public_keys)-1)/2)
                        checkpoint_proof =  checkpoint_proof[tp_temp+1:]
                else:
                    logger.error("Validation of checkpoint proof failed. Becomming immutable and sending a reconfig request to Olympus")
                    send_reconfig('CheckpointProof')
                    return
            # Send return shuttles if we are not the head
            if not self.head:
                # Forward the result shuttle to the previous replica
                return_payload = (request.get_body(), result, result_proofs, checkpoint_num, checkpoint_proof)
                send(("ResultShuttle", return_payload), to=self.prev_replica)
                logger.debug("Sent Return Shuttle for Client: " + str(request.client_id) + " Request ID:"
                             + str(request.request_id) + " to Replica: " + str(self.prev_replica))
        else:
            # Become immutable and ask olympus for a reconfigure
            logger.error("2 Validation of return shuttle failed for Client: " + str(request.client_id) + " Request ID: "
                         + str(request.request_id) + " from: " + str(sender))
            logger.info("Becomming immutable and asking for a reconfig")
            send_reconfig('ResultShuttle')
            return

    # Handler for a wedge request from Olympus
    def receive(msg=("wedgeRequest", m), from_=sender):
        logger.debug("Received a wedge request from: " + str(sender))
        update_trigger_flags_new(4)  # update trigger for wedge request
        if self.drop_flag:                # drop if drop_flag is True
            self.drop_flag = False
            return

        # Ignore if the sender is not olympus
        if sender != self.olympus:
            logger.debug("Ignoring wedge request because the sender is not olympus")
            return
        logger.info("Received a wedge request from Olympus. Wedging...")

        # Set status to immutable
        self.status = STATUS.IMMUTABLE
        hashed_state = nacl.hash.sha256(pickle.dumps(self.state))

        if self.truncate_history_flag:
            temp_keys_to_delete = []

        # Send checkpoint proofs
        wedge_payload = (self.configuration, self.state, self.order_history, self.latest_checkpoint_slot, self.latest_checkpoint_proof)
        # Send replica state and configuration number

        return send(("wedgeResponse", wedge_payload), to=self.olympus)

    # Handler for catchup requests from Olympus
    def receive(msg=("catchupRequest", m), from_=sender):
        # Ignore if the sender is not olympus
        if sender != self.olympus:
            logger.debug("Ignoring catchup request because the sender is not olympus")
            return
        logger.info("Received a catchup request from Olympus. Catching up...")

        update_trigger_flags_new(9)
        if self.drop_flag:   # drop if the drop flag is True
            self.drop_flag = False
            return

        catchup_history = m
        # Run all operations that are missing
        slots = list(catchup_history.keys())
        slots.sort()
        for slot in slots:
            if slot > self.last_slot_number:
                request = pickle.loads(catchup_history[slot][0].message)[1]
                logger.debug('Catching up for request: ' + str(request))
                order_command(request)

        # Send state and hashed state
        hashed_state = nacl.hash.sha256(pickle.dumps(self.state))
        catchup_payload = (self.configuration, hashed_state, self.state)
        # Send replica state and configuration number
        return send(("catchupResponse", catchup_payload), to=self.olympus)
